#!/bin/bash

# ================= é…ç½®åŒº =================
DATA_DIR="code/data" 
# =========================================

RESULT_DIR="test_results_small"
CSV_FILE="$RESULT_DIR/metrics.csv"
mkdir -p $RESULT_DIR/logs

# åˆå§‹åŒ– CSV
echo "algorithm,dataset,job_id,total_execution_time,avg_iteration_time,network_communication,peak_memory_usage,iterations_to_converge,convergence_rate,cpu_utilization" > $CSV_FILE

# çŽ¯å¢ƒå˜é‡
export HADOOP_CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath):$(pwd)/pagerank-compare.jar
export GIRAPH_JAR=/usr/local/hadoop/share/hadoop/yarn/lib/giraph.jar

# ðŸ”´ åªå®šä¹‰ small ä¸€ä¸ªæ•°æ®é›†
declare -A DATASETS
DATASETS=( ["small"]="cit-HepPh.txt" )

# 1. é¢„å¤„ç†
echo ">>> Step 1: Preprocessing Data..."
for name in "${!DATASETS[@]}"; do
    raw_file="$DATA_DIR/${DATASETS[$name]}"
    if [ -f "$raw_file" ]; then
        echo "Processing $name..."
        java -cp classes DataPreprocess "$raw_file" "${name}_mr.txt" "${name}_giraph.txt"
        
        hdfs dfs -mkdir -p /user/root/input/$name
        hdfs dfs -put -f "${name}_mr.txt" /user/root/input/$name/mr.txt
        hdfs dfs -put -f "${name}_giraph.txt" /user/root/input/$name/giraph.txt
    else
        echo "âš ï¸ Error: $raw_file not found!"
        exit 1
    fi
done

# 2. è¿è¡Œå¾ªçŽ¯ (åªè·‘ 1 æ¬¡ç”¨äºŽæµ‹è¯•)
for name in "${!DATASETS[@]}"; do
    for algo in "giraph" ; do
        # ðŸ”´ è¿™é‡Œæ”¹æˆåªè·‘ 1 æ¬¡
        for run in 1; do
            echo "=========================================================="
            echo "TEST RUN: $algo on $name"
            echo "=========================================================="

            echo ">>> Restarting Cluster..."
            stop-all.sh > /dev/null 2>&1
            sleep 5
            start-all.sh > /dev/null 2>&1
            sleep 10
            hdfs dfsadmin -safemode leave > /dev/null 2>&1

            JOB_ID="${algo}_${name}_test"
            LOG="$RESULT_DIR/logs/${JOB_ID}.log"
            MON="$RESULT_DIR/logs/${JOB_ID}_mon.log"
            hdfs dfs -rm -r /user/root/output/$JOB_ID > /dev/null 2>&1
            
            sar -u -r 1 > $MON 2>&1 &
            MON_PID=$!

            start_ts=$(date +%s)

            if [ "$algo" == "giraph" ]; then
                hadoop jar $GIRAPH_JAR \
                    org.apache.giraph.GiraphRunner \
                    PageRankGiraph \
                    -mc PageRankMasterCompute \
                    -vif org.apache.giraph.io.formats.JsonLongDoubleFloatDoubleVertexInputFormat \
                    -vip /user/root/input/$name/giraph.txt \
                    -vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat \
                    -op /user/root/output/$JOB_ID \
                    -w 1 -ca giraph.SplitMasterWorker=false > $LOG 2>&1
            else
                hadoop jar pagerank-compare.jar \
                    PageRankMapReduce \
                    /user/root/input/$name/mr.txt \
                    /user/root/output/$JOB_ID > $LOG 2>&1
            fi

            end_ts=$(date +%s)
            duration=$((end_ts - start_ts))
            kill $MON_PID

            # --- E. æŠ“å–ä»ŽèŠ‚ç‚¹æ—¥å¿— (å…³é”®æ­¥éª¤) ---  
            # MapReduce ä¸éœ€è¦è¿™ä¸€æ­¥ï¼Œå› ä¸ºå®ƒæ‰“å°åœ¨ Driver ä¸Š
            # Giraph éœ€è¦åŽ» Slave èŠ‚ç‚¹æŠ“å– finishSuperstep æ—¥å¿—
            if [ "$algo" == "giraph" ]; then
                echo ">>> Hunting for Giraph logs on Slave nodes..."
                
                # ä»Žä¸»æ—¥å¿—ä¸­æå– Application ID
                APP_ID=$(grep -o "application_[0-9_]*" $LOG | head -1)
                
                if [ -n "$APP_ID" ]; then
                    # éåŽ†æ‰€æœ‰èŠ‚ç‚¹ (Master, Slave1, Slave2)
                    for node in master slave1 slave2; do
                        echo "    Fetching from $node..."
                        # è¿œç¨‹æ‰§è¡Œ grepï¼ŒæŸ¥æ‰¾ finishSuperstepï¼Œå¹¶å°†ç»“æžœè¿½åŠ åˆ°æœ¬åœ° LOG æ–‡ä»¶
                        # 2>/dev/null ç”¨äºŽå±è”½ SSH çš„è¿žæŽ¥è­¦å‘Šä¿¡æ¯
                        ssh $node "grep -r 'finishSuperstep' /usr/local/hadoop/logs/userlogs/$APP_ID 2>/dev/null" >> $LOG
                    done
                else
                    echo "    âš ï¸ Warning: Could not find Application ID, skipping log fetch."
                fi
            fi

            echo ">>> Parsing results..."
            java -cp classes LogAnalyzer $algo $name $JOB_ID $LOG $MON $duration >> $CSV_FILE
            
            echo ">>> Finished in ${duration}s"
        done
    done
done

echo "âœ… Test Completed! Check $CSV_FILE"
